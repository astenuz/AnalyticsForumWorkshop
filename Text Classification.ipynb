{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Clasificando noticias", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#!pip install spacy\n#!python -m spacy download es\n#!pip install stop_words\n#!pip install dplython"
        }, 
        {
            "source": "## Librerias", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import spacy\nfrom stop_words import get_stop_words\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\nfrom sklearn.pipeline import Pipeline\n#from sklearn.svm import LinearSVC\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd \nfrom dplython import (DplyFrame, X, diamonds, select, sift, sample_n,\n    sample_frac, head, arrange, mutate, group_by, summarize, DelayFunction) "
        }, 
        {
            "source": "## Cargamos noticias", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Los datos vienen de distintas versiones digitales de los periodicos Eltiempo, Portafolio, Clarin, El mundo, El pais, 20minutos y Expansion. Recopilamos alrededor de 900 noticias en temas de deportes, politica, economia y tecnologia. Para cada noticia se ha recolectado la categoria, la url y el contenido en texto. Estos datos se encuentran en una base de datos HIVE.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#Coloque aqui Credenciales HIVE"
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# The code was removed by DSX for sharing."
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- categoria: string (nullable = true)\n |-- url: string (nullable = true)\n |-- contenido: string (nullable = true)\n\n+---------+--------------------+--------------------+\n|categoria|                 url|           contenido|\n+---------+--------------------+--------------------+\n| economia|http://www.eltiem...|Un crecimiento de...|\n| economia|http://www.eltiem...|Con los 14 despid...|\n| economia|http://www.eltiem...|En comparaci\u00f3n co...|\n| economia|http://www.eltiem...|Residir en el ext...|\n| economia|http://www.eltiem...|En marzo, el tope...|\n| economia|http://www.eltiem...|                    |\n| economia|http://www.eltiem...|Quitarle los tres...|\n| economia|http://www.eltiem...|Colombia ascendi\u00f3...|\n| economia|http://www.eltiem...|Durante este mi\u00e9r...|\n| economia|http://www.eltiem...|Las contingencias...|\n+---------+--------------------+--------------------+\nonly showing top 10 rows\n\n"
                }
            ], 
            "source": "from ingest.Connectors import Connectors\nfrom pyspark.sql import SQLContext\n\nsqlContext = SQLContext(sc)\n\nHiveloadOptions = { Connectors.Hive.HOST                        : hive_credentials[\"host\"],\n                      Connectors.Hive.PORT                      : hive_credentials[\"port\"],\n                      Connectors.Hive.DATABASE                  : hive_credentials[\"database\"],\n                      Connectors.Hive.USERNAME                  : hive_credentials[\"username\"],\n                      Connectors.Hive.PASSWORD                  : hive_credentials[\"password\"],\n                      Connectors.Hive.SOURCE_TABLE_NAME         : \"noticias_sr\"}\n\nhive_df = sqlContext.read.format(\"com.ibm.spark.discover\").options(**HiveloadOptions).load()\nhive_df.printSchema()\nhive_df.show(10)"
        }, 
        {
            "source": "para procesar los datos preferimos pasarlos al entorno \"local\". Pasamos de HIVE a Pandas", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 12, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/socket.py:647: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('127.0.0.1', 48168), raddr=('127.0.0.1', 41057)>\n  self._sock = None\n"
                }
            ], 
            "source": "news_df = hive_df.toPandas()"
        }, 
        {
            "source": "Quitamos espacios y saltos de linea a los extremos de url y texto", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 13, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def safestrip(x):\n    if x is None:\n        return ''\n    else:\n        return x.strip()\n\n\ndef vecstrip(series):\n    return series.map(lambda x: safestrip(x))"
        }, 
        {
            "execution_count": 14, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "news_df = (news_df >> \n  mutate(url=vecstrip(X.url), contenido = vecstrip(X.contenido)))"
        }, 
        {
            "source": "Filtramos las filas que no tienen texto", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 15, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "news_df = news_df.query('contenido != \"\"')"
        }, 
        {
            "source": "Demos un vistazo a las noticias", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 16, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 16, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>categoria</th>\n      <th>url</th>\n      <th>contenido</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>economia</td>\n      <td>http://www.eltiempo.com/economia/sectores/cart...</td>\n      <td>Un crecimiento de 7,7 por ciento tuvo el saldo...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>economia</td>\n      <td>http://www.eltiempo.com/economia/sectores/desp...</td>\n      <td>Con los 14 despidos que se produjeron en la te...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>economia</td>\n      <td>http://www.eltiempo.com/economia/sectores/dese...</td>\n      <td>En comparaci\u00f3n con la tasa de desempleo\u00a0de ene...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>economia</td>\n      <td>http://www.eltiempo.com/economia/finanzas-pers...</td>\n      <td>Residir en el exterior no es un obst\u00e1culo para...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>economia</td>\n      <td>http://www.eltiempo.com/economia/sector-financ...</td>\n      <td>En marzo, el tope m\u00e1ximo que tendr\u00e1n las tasas...</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "  categoria                                                url  \\\n0  economia  http://www.eltiempo.com/economia/sectores/cart...   \n1  economia  http://www.eltiempo.com/economia/sectores/desp...   \n2  economia  http://www.eltiempo.com/economia/sectores/dese...   \n3  economia  http://www.eltiempo.com/economia/finanzas-pers...   \n4  economia  http://www.eltiempo.com/economia/sector-financ...   \n\n                                           contenido  \n0  Un crecimiento de 7,7 por ciento tuvo el saldo...  \n1  Con los 14 despidos que se produjeron en la te...  \n2  En comparaci\u00f3n con la tasa de desempleo\u00a0de ene...  \n3  Residir en el exterior no es un obst\u00e1culo para...  \n4  En marzo, el tope m\u00e1ximo que tendr\u00e1n las tasas...  "
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "news_df.head()"
        }, 
        {
            "source": "Podemos ver cuantas noticias tenemos en cada categoria", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 17, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 17, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>contenido</th>\n    </tr>\n    <tr>\n      <th>categoria</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>deportes</th>\n      <td>988</td>\n      <td>988</td>\n    </tr>\n    <tr>\n      <th>economia</th>\n      <td>460</td>\n      <td>460</td>\n    </tr>\n    <tr>\n      <th>politica</th>\n      <td>217</td>\n      <td>217</td>\n    </tr>\n    <tr>\n      <th>tecnologia</th>\n      <td>367</td>\n      <td>367</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "            url  contenido\ncategoria                 \ndeportes    988        988\neconomia    460        460\npolitica    217        217\ntecnologia  367        367"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "news_df.groupby('categoria').count()"
        }, 
        {
            "source": "Es claro que tenemos cierto imbalance en los datos, mas adelante veremos si esto cohibe los resultados de los algoritmos.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Desarrollo del algoritmo", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Vamos a desarrollar un modelo que aprenda a clasificar noticias usando las palabras que se encuentran en los articulos.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "En este momento los datos se encuentran limpios, siguen siendo el texto de una noticia habitual que leeriamos. Debemos transformar este texto a una representacon que un computador/algoritmo pueda usar para realizar predicciones.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "## Separamos los datos en train y test", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "El primer paso que debemos realizar con los datos es separarlos en dos conjuntos. Un de entrenamiento que el algoritmo usara para aprender y uno de prueba que luego de aprender servira para ver que tan bueno es el algoritmo.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "news_train, news_test, cat_train, cat_test = train_test_split(\n    news_df.drop(\"categoria\", axis = 1), news_df[\"categoria\"], test_size=0.25, random_state=42)"
        }, 
        {
            "source": "## Tokenizer con spaCy", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Ahora pasamos a la transformacion del texto plano a una representacion que algoritmos de machine learning puedan manejar.\nEscogemos bag of words, una de las mas simples, pero utiles que existen. En orden de obtener la representacion, primero debemos pasar a traves de cada texto y separarlo en tokens.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 19, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n/usr/local/src/conda3_runtime/home/envs/DSX-Python35-Spark/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n  return f(*args, **kwds)\n/gpfs/fs01/user/se1f-2003f1257f20bb-7f578b9e48a9/.local/lib/python3.5/site-packages/msgpack_numpy.py:179: PendingDeprecationWarning: encoding is deprecated, Use raw=False instead.\n  return _unpacker.unpack(stream, encoding=encoding, **kwargs)\n"
                }
            ], 
            "source": "#import spacy\n\nnlp = spacy.load('es')"
        }, 
        {
            "source": "Aca definimos tokens que no aportan a la diferenciacion de categorias, como signos de puntuacion y palabras muy usadas como \"el\", \"a\", etc. Estos seran removidos al extraer los tokens de los articulos.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 20, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#from stop_words import get_stop_words\n\nSTOPLIST = get_stop_words('es')\n\n#import string\nSYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-----\", \"---\", \"...\", \"\u201c\", \"\u201d\", \"'ve\"]\n\nWHITES = [\"\", \" \", \"\\n\", \"\\n\\n\"]"
        }, 
        {
            "source": "Esta funcion se encarga de separar el texto en tokens y ademas de hacer un proceso llamado lematizacion.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 21, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def tokenizeText(sample):\n\n    # get the tokens using spaCy\n    raw_tokens = nlp(sample)\n\n    # lemmatize\n    tokens = [tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_ for tok in raw_tokens]\n\n    # stoplist the tokens\n    tokens = [tok for tok in tokens if tok not in STOPLIST]\n    \n    tokens = [tok for tok in tokens if tok not in SYMBOLS]\n    \n    tokens = [tok for tok in tokens if tok not in WHITES]\n    \n    #print(tokens[0:2])\n    \n    # remove large strings of whitespace\n    #while \"\" in tokens:\n    #    tokens.remove(\"\")\n    #while \" \" in tokens:\n    #    tokens.remove(\" \")\n    #while \"\\n\" in tokens:\n    #    tokens.remove(\"\\n\")\n    #while \"\\n\\n\" in tokens:\n    #    tokens.remove(\"\\n\\n\")\n\n    return tokens"
        }, 
        {
            "source": "Probemos la funcion", 
            "cell_type": "raw", 
            "metadata": {}
        }, 
        {
            "execution_count": 22, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 22, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "['hola', 'nombrar', 'ser', 'david']"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "tokenizeText(\"Hola, mi nombre es David\")"
        }, 
        {
            "source": "Teniendo una forma de separar en tokens, podemos generar la representacion de conteos de bag-of-words. PAra esto hacemos uso de la libreria scikit-learn. Como parametro le pasamos la funcion que definimos para hacer la tokenizacion.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "vectorizer = CountVectorizer(tokenizer = tokenizeText, ngram_range=(1,1))"
        }, 
        {
            "source": "Al aplicar la funcion fit_transform sobre los datos de entrenamiento, el vectorizador aprende el vocabulario y devuelve la representacion en conteos de cada uno de los articulos.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 24, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "train_counts = vectorizer.fit_transform(news_train.contenido)"
        }, 
        {
            "source": "La variable train_counts es una gran matriz donde cada columna representa un token y cada fila un articulo. En la celda esta el conteo de cuantas veces dicha palabra aparece en el articulo.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 25, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 25, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "(1524, 27370)"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "train_counts.shape"
        }, 
        {
            "source": "## Conteos y Tf-Idf", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "La representacion de conteos tiene algunos problemas. Por ejemplo, que pasa con articulos mas largos?, tambien, que pasa con palabras que todos los articulos comparten.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Una mejor representacion es la representacion Tf-Idf. En scikit-learn la calculamos de igual manera que hicimos con los conteos.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 26, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "tf_transformer = TfidfTransformer(use_idf=True)\ntrain_tfidf = tf_transformer.fit_transform(train_counts)"
        }, 
        {
            "source": "## Modelo de clasificacion en scikit-learn", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Compararemos dos algoritmos populares, NaiveBayes y SVM(sgd).", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 27, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sgd = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\nnb = MultinomialNB()"
        }, 
        {
            "source": "Realizamos el entrenamiento", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 28, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sgd_mod = sgd.fit(train_tfidf, cat_train)\nnb_mod = nb.fit(train_tfidf, cat_train)"
        }, 
        {
            "source": "Probamos con los datos de test, primero Naive Bayes y luego SVM", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "Transformamos los datos de test para que queden como tf-idf, lo que los modelos esperan.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 29, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "test_counts = vectorizer.transform(news_test.contenido)\ntest_tfidf = tf_transformer.transform(test_counts)"
        }, 
        {
            "source": "Entrenamiento de modelos", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 30, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "sgd_test_preds = sgd_mod.predict(test_tfidf)\nnb_test_preds = nb_mod.predict(test_tfidf)"
        }, 
        {
            "source": "Ahora, revisamos resultados para los modelos", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "* Naive bayes", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 31, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 31, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.77952755905511806"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "accuracy_score(cat_test, nb_test_preds)"
        }, 
        {
            "execution_count": 32, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 32, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[ 83,  38,   0,   4],\n       [  0, 237,   0,   0],\n       [  7,  48,   0,   1],\n       [  3,  11,   0,  76]])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "confusion_matrix(cat_test, nb_test_preds, labels=['economia','deportes','politica', 'tecnologia'])"
        }, 
        {
            "source": "* SVM (SGD)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 33, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 33, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "0.96062992125984248"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "accuracy_score(cat_test, sgd_test_preds)"
        }, 
        {
            "execution_count": 34, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 34, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "array([[114,   4,   1,   6],\n       [  1, 236,   0,   0],\n       [  4,   2,  50,   0],\n       [  2,   0,   0,  88]])"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "confusion_matrix(cat_test, sgd_test_preds, labels=['economia','deportes','politica', 'tecnologia'])"
        }, 
        {
            "source": "### Vamos a probar con noticias de hoy", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 35, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "noticia_1 = \"\"\"De acuerdo con el fallo del Tribunal Superior de Bogot\u00e1 el expresidente y hoy senador \u00c1lvaro Uribe Velez debe retractarse de las afirmaciones deshonrosas que realiz\u00f3 a trav\u00e9s de su cuenta de Twitter contra el periodista Daniel Coronell. Los hechos ocurrieron el 10 de febrero de 2018 cuando el congresista escribi\u00f3 el siguiente mensaje: \"Daniel Coronel procede con una actitud mafiosa para hacer da\u00f1o electoral, sus negocios con narcotr\u00e1fico siguen impunes y me ha demandado porque pienso que ser\u00eda extraditable\". Para el Tribunal, se deben proteger los derechos al buen nombre y honra del comunicador, los cuales fueron vulnerados por Uribe al publicar este mensaje.\n\n(En contexto: La pelea entre \u00c1lvaro Uribe y Daniel Coronell)\n\nDicho trino se dio tras la publicaci\u00f3n de la columna del periodista en la Revista Semana \"Aqu\u00ed no hay muertos\" en la que revel\u00f3 un correo del ex paramilitar Diego Fernando Murillo, mejor conocido como Don Berna, en el que se\u00f1alar\u00eda a Uribe como el responsable de la muerte del empresario colombiano Pedro Juan Moreno.\n\nUno de los principales argumentos de este Tribunal tiene que ver con el gran n\u00famero de seguidores con que cuentan, tanto el senador como el periodista, en sus diversas redes sociales y la magnitud del da\u00f1o moral que caus\u00f3 el mensaje del congresista. El trino habr\u00eda tenido como \u00fanico fin \"producir da\u00f1os a la integridad moral en su doble acepci\u00f3n: buen nombre y honra, hechas p\u00fablicas sin justificaci\u00f3n constitucionalmente v\u00e1lida\", asegur\u00f3 el Tribunal. Por este motivo el magistrado Jairo Jos\u00e9 Agudelo consider\u00f3 que se deb\u00eda hacer la retractaci\u00f3n.\n\nRecordemos que \u00c1lvaro Uribe Velez ya hab\u00eda pasado por una situaci\u00f3n similar. En agosto del a\u00f1o pasado el mismo Tribunal orden\u00f3 al expresidente rectificar las acusaciones hechas en contra de Daniel Samper Ospina, cuando se refiri\u00f3 a \u00e9l como un \"violador de ni\u00f1os\". En su momento, el abogado defensor de Uribe, Jaime Lombana, argument\u00f3 que no hab\u00eda fundamento jur\u00eddico alguno para reprochar a Uribe Velez y pidi\u00f3 tumbar el fallo del Tribunal. Sin embargo, el senador termin\u00f3 retract\u00e1ndose de sus afirmaciones en un evento p\u00fablico en la cuidad de Barranquilla.\"\"\""
        }, 
        {
            "execution_count": 36, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "noticia_2 = \"\"\"Sergio Luis Henao es un hombre que es ejemplo de perseverancia, lucha y entrega. De cada ca\u00edda que ha sufrido, se ha levantado m\u00e1s fuerte. Aunque los m\u00e9dicos llegaron a pronosticarle que no podr\u00eda volver a montar en bicicleta, tras fracturarse su rodilla derecha en ocho pedazos, este antioque\u00f1o sali\u00f3 adelante. Con el apoyo de su familia ha superado cada una de sus crisis y ahora vive el mejor momento de su carrera. (Tambi\u00e9n puede leer: Sergio Luis, te escribe tu hermano)\n\nEl ciclista antioque\u00f1o es uno de los referentes del Team Sky y tras ganar dos veces el campeonato nacional de ruta en Colombia y obtener el t\u00edtulo de la Paris \u2013 Niza 2017, este a\u00f1o buscar\u00e1 repetir esa victoria. Desde este domingo participar\u00e1 en la edici\u00f3n 76 de esta competencia. Tambi\u00e9n estar\u00e1n los colombianos Esteban Chaves (Mitchelton Scott), Jarlinson Pantano (Trek) y Dayer Quintana (Movistar). (Le puede interesar: Sergio Luis Henao, campe\u00f3n de la Par\u00eds-Niza 2017)\n\nEl Espectador recuerda esta entrevista que le dio el corredor de Rionegro hace un a\u00f1o, despu\u00e9s de ganar la Paris \u2013 Niza.\n\n\u00bfDe d\u00f3nde viene esa berraquera?\n\nEs de familia, mis padres desde peque\u00f1o me inculcaron unos valores muy bonitos. El sacrificio, el luchar por las cosas, el creer. Tengo una familia muy unida, amorosa, y eso lo motiva a uno a luchar y a tener berraquera. Crec\u00ed con unas condiciones econ\u00f3micas muy dif\u00edciles, como muchas familias colombianas. Nuestro padre con el sueldo de celador de una florister\u00eda nos pudo sacar adelante a todos, terminamos el bachillerato y luego cada uno eligi\u00f3 qu\u00e9 hacer de su futuro.\n\n\u00bfCu\u00e1ndo se decidi\u00f3 por el ciclismo?\n\nTendr\u00eda unos 12 a\u00f1os cuando mi pap\u00e1 me regal\u00f3 la primera bicicleta, un casco y un uniforme. \u00c9l en alg\u00fan momento compiti\u00f3, as\u00ed que fue fundamental porque me ense\u00f1\u00f3 a pedalear y me motiv\u00f3.\n\n\u00bfQu\u00e9 recuerda de esa primera bicicleta?\n\nLa utilic\u00e9 por primera vez en una carrerita en Rionegro. No me fue tan bien porque tuve una ca\u00edda y no pude disputar el embalaje final. Pero ah\u00ed se empieza a aprender de las ca\u00eddas, nada es f\u00e1cil. Recuerdo que era marca Torres, color verde y de aluminio. Creo que en ese momento le debi\u00f3 haber costado a mi pap\u00e1 unos $200.000.\n\n\u00bfY cu\u00e1nto tiempo le dur\u00f3?\n\nComenc\u00e9 a tener buenos resultados, as\u00ed que fui mejorando poco a poco. Luego tuve una de carbono, luego otra mejor, hasta que tuve la opci\u00f3n de entrar como juvenil al Orgullo Paisa.\n\n\u00bfEn ese proceso formativo en alg\u00fan momento pens\u00f3 en dedicarse a otra cosa?\n\nS\u00ed. Yo quer\u00eda comenzar a ayudar r\u00e1pidamente en mi casa, a llevar un mercado o cosas a mis hermanos y pap\u00e1s, pero el ciclismo no era muy rentable. Ganaba un sueldo peque\u00f1o como juvenil en el Orgullo Paisa y los premios de las carreritas que ganaba no eran muy grandes. As\u00ed que ve\u00eda a primos y personas de mi edad que ganaban m\u00e1s que yo y pensaba en tirar la toalla y buscar otra manera de contribuir en casa.\n\n\u00bfQu\u00e9 hubiera sido de Sergio Luis sin el ciclismo?\n\nEn los momentos m\u00e1s duros, en los que quer\u00eda tirar todo lejos, me daban ganas como de comprar un taxi y ponerme a trabajar. Pero eso lo piensa uno con la cabeza caliente. Nunca desist\u00ed.\n\nNi siquiera con su primer gran golpe en una carrera en Francia antes del Tour de L\u2019Avenir\u2026\n\nNi ah\u00ed. Afortunadamente en mi proceso de recuperaci\u00f3n conoc\u00ed a mi esposa Carolina Caicedo, quien era fisioterapeuta de Coldeportes. Ella fue fundamental para no dejarme rendir y para motivarme a seguir adelante. En medio del dolor y la crisis, tambi\u00e9n quedan cosas buenas.\n\n\u00bfSi no es por Carolina se retira del ciclismo en 2012, luego de la ca\u00edda en la Vuelta a Suiza?\n\nMe hab\u00edan desahuciado para el ciclismo. La rodilla se me fractur\u00f3 en ocho pedazos. Fue duro, pero ah\u00ed estuvo mi esposa y sin ella hubiese sido imposible salir adelante. An\u00edmicamente estuve muy derrotado, hubo peleas y sufrimiento, pero salimos adelante juntos. Si los m\u00e9dicos me dec\u00edan que no se pod\u00eda, ella me dec\u00eda que s\u00ed. Fue una berraca, paciente para aguantarme y me levant\u00f3.\n\n\u00bfPero usted lleg\u00f3 a dudar?\n\nS\u00ed. La verdad es que fueron meses en los que no pod\u00eda ni caminar y me tocaba depender de alguien para moverme. Adem\u00e1s, los expertos no dec\u00edan nada bueno, as\u00ed que me desanimaba y pensaba que ser\u00eda el final de mi carrera.\n\n\u00bfAhora qu\u00e9 siente cuando se ve esa cicatriz en la rodilla derecha?\n\nLa veo y me siento un berraco. Fue algo duro pero que no me venci\u00f3 y ahora cuando camino y veo lo que hago, le doy gracias a Dios y a la vida por c\u00f3mo me funciona de bien esa rodilla. Esa cicatriz me llena de orgullo.\n\n\u00bfEl t\u00edtulo del Campeonato Nacional de Ruta en 2017 fue lo que necesitaba para olvidar el golpe en R\u00edo 2016?\n\nEso de R\u00edo nunca lo olvidar\u00e9. En el momento de la ca\u00edda sent\u00ed much\u00edsimo dolor, pero luego, en el hospital, me dio mucha rabia. Ten\u00eda una oportunidad \u00fanica, pero Dios sabe c\u00f3mo hace sus cosas. Me impresion\u00f3 el apoyo de la gente en Bogot\u00e1, como que todos hab\u00edan sentido mi dolor en R\u00edo y en la ca\u00edda de ese d\u00eda en el campeonato nacional, as\u00ed que quer\u00edan que fuera yo el ganador. Di todo de m\u00ed y afortunadamente pude sentir por primera vez lo que era un triunfo de este tipo.\n\nY luego lleg\u00f3 la Par\u00eds-Niza 2017\u2026\n\nSer el campe\u00f3n nacional de ruta me llen\u00f3 de cosas positivas. Me motiv\u00f3 much\u00edsimo y creo que llevar el tricolor en la Par\u00eds-Niza hizo que sintiera algo diferente. Uno desde que comienza en el ciclismo aspira a ganar carreras de este tipo y la verdad, cuando lo logr\u00e9, ni me lo cre\u00eda.\n\nJusto estos triunfos llegaron tras el nacimiento de Emanuel, su primog\u00e9nito\u2026\n\nEmanuel es mi motivaci\u00f3n, es querer ser su orgullo, su ejemplo. Ser un buen gu\u00eda para \u00e9l. Cuando salgo a entrenar o voy a competir y lo dejo solo, le pido a Dios que pueda regresar con salud para verle sus ojitos.\n\nSu gloria ha sido muy sufrida, \u00bfno?\n\n(Risas) La verdad es que el sufrimiento como que es algo caracter\u00edstico en m\u00ed. Nada es f\u00e1cil y cuando se gana as\u00ed, se disfruta m\u00e1s.\n\nUsted le ense\u00f1a al pueblo colombiano que de todas las ca\u00eddas hay que levantarse y seguir luchando, \u00bfes consciente de eso?\n\nEl pueblo colombiano ha sufrido la violencia, la corrupci\u00f3n de nuestros pol\u00edticos, pero siempre nos levantamos y somos gente berraca, que a pesar de todo es feliz y sale adelante de los momentos m\u00e1s complicados. Es bonito que yo pueda ser ejemplo de eso en el mundo entero. Soy un colombiano que nunca se rinde.\n\n\u00bfC\u00f3mo es Chris Froome como jefe?\n\n\u00c9l es una excelente persona, un gran l\u00edder. Muy sereno, humilde, agradecido con sus compa\u00f1eros y tiene una gran relaci\u00f3n con todos. \u00c9l me respeta mucho, yo lo admiro y siempre soy leal con \u00e9l. Le he aprendido muchas cosas, c\u00f3mo correr y c\u00f3mo esforzarse.\n\n\u00bfLe sorprendi\u00f3 que fuera a verlo coronarse campe\u00f3n de la Par\u00eds-Niza 2017?\n\n\u00c9l es as\u00ed. Sent\u00ed mucho orgullo por recibir ese mensaje que me puso en Twitter. Es una persona excepcional y un deportista ejemplar.\n\n\u00bfC\u00f3mo asumieron en el Sky su t\u00edtulo del campeonato nacional?\n\nCuando llegu\u00e9 a Europa y vi la camiseta que me dise\u00f1aron, me motiv\u00f3 much\u00edsimo porque le dan el valor que es ser el campe\u00f3n nacional en Colombia. Ellos saben lo duro que es competir y ganar ac\u00e1 y han valorado mucho mi triunfo. Para m\u00ed es m\u00e1s que un orgullo llevar a Colombia en el pecho por las carreteras del mundo.\"\"\""
        }, 
        {
            "execution_count": 37, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "noticias = [noticia_1, noticia_2]"
        }, 
        {
            "execution_count": 38, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "noticias_counts = vectorizer.transform(noticias)\nnoticias_tfidf = tf_transformer.transform(noticias_counts)"
        }, 
        {
            "execution_count": 42, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "['politica' 'deportes']\n"
                }
            ], 
            "source": "noticias_preds = sgd_mod.predict(noticias_tfidf)\nprint(noticias_preds)"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}